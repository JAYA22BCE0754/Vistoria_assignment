{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "cfcuvrbmgpveex4e55qb",
   "authorId": "5259043861246",
   "authorName": "JAYA22BCE0754",
   "authorEmail": "jayavardhand2004@gmail.com",
   "sessionId": "6f7ceb58-bd19-444e-baaf-ea31e8389592",
   "lastEditTime": 1759055325027
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.functions import col\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsales_table = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.STORE_SALES\") \\\n    .select(\n        col(\"SS_ITEM_SK\").alias(\"item_sk\"),\n        col(\"SS_STORE_SK\").alias(\"store_sk\"),\n        col(\"SS_QUANTITY\").alias(\"quantity\"),\n        col(\"SS_SALES_PRICE\").alias(\"sales_price\")\n    ) \\\n    .filter(col(\"SS_SALES_PRICE\").is_not_null()) \\\n    .limit(10000)  # Limit to 10k rows for faster processing\n\nsales_table.show(5)\ndf = sales_table.to_pandas()\ndf.columns = [c.lower() for c in df.columns]  # lowercase column names\nX = df[['item_sk', 'store_sk', 'quantity']]\ny = df['sales_price']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f\"MSE: {mse:.2f}, R2: {r2:.2f}\")\npredictions_df = pd.DataFrame({\n    'item_sk': X_test['item_sk'].values,\n    'store_sk': X_test['store_sk'].values,\n    'quantity': X_test['quantity'].values,\n    'actual_sales_price': y_test.values,\n    'predicted_sales_price': y_pred\n})\npredictions_snowpark = session.create_dataframe(predictions_df)\nsession.sql(\"CREATE DATABASE IF NOT EXISTS MY_DB\").collect()\nsession.sql(\"CREATE SCHEMA IF NOT EXISTS MY_DB.MY_SCHEMA\").collect()\npredictions_snowpark.write.mode(\"overwrite\").save_as_table(\"MY_DB.MY_SCHEMA.SALES_PREDICTIONS\")\npredictions_snowpark\npred_pd = predictions_snowpark.limit(1000).to_pandas()\nplt.figure(figsize=(8,6))\nsns.scatterplot(\n    x='actual_sales_price',\n    y='predicted_sales_price',\n    data=pred_pd,\n    alpha=0.6\n)\nplt.plot(\n    [pred_pd['actual_sales_price'].min(), pred_pd['actual_sales_price'].max()],\n    [pred_pd['actual_sales_price'].min(), pred_pd['actual_sales_price'].max()],\n    color='red', linestyle='--'\n)\nplt.title(\"Actual vs Predicted Sales Price\")\nplt.xlabel(\"Actual Sales Price\")\nplt.ylabel(\"Predicted Sales Price\")\nplt.show()\n\n# Error distribution\npred_pd['error'] = pred_pd['predicted_sales_price'] - pred_pd['actual_sales_price']\nplt.figure(figsize=(8,5))\nsns.histplot(pred_pd['error'], bins=50, kde=True)\nplt.title(\"Prediction Error Distribution\")\nplt.xlabel(\"Error\")\nplt.ylabel(\"Count\")\nplt.show()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6c9ce1f6-c8d1-403f-ae41-93514ef5d29e",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import snowflake.snowpark as snowpark\nfrom snowflake.snowpark.functions import col\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.impute import SimpleImputer\n\nsales_table = session.table(\"SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.STORE_SALES\") \\\n    .select(\n        col(\"SS_ITEM_SK\").alias(\"item_sk\"),\n        col(\"SS_STORE_SK\").alias(\"store_sk\"),\n        col(\"SS_QUANTITY\").alias(\"quantity\"),\n        col(\"SS_SALES_PRICE\").alias(\"sales_price\")\n    ) \\\n    .filter(col(\"SS_SALES_PRICE\").is_not_null())\\\n    .limit(10000)\n\nsales_table.show(5)\ndf = sales_table.to_pandas()\ndf.columns = [c.lower() for c in df.columns]\n# Drop rows with NaN (or alternatively use SimpleImputer)\ndf = df.dropna(subset=['item_sk', 'store_sk', 'quantity', 'sales_price'])\n\n# Alternatively, to impute missing values:\n# imputer = SimpleImputer(strategy='median')\n# X_imputed = imputer.fit_transform(df[['item_sk', 'store_sk', 'quantity']])\nX = df[['item_sk', 'store_sk', 'quantity']]\ny = df['sales_price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nmodels = {\n    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42,n_jobs=1),\n    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n    \"LinearRegression\": LinearRegression(),\n    \"HistGradientBoosting\": HistGradientBoostingRegressor(max_iter=100, random_state=42)  # handles NaN directly\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    results[name] = {'model': model, 'y_pred': y_pred, 'mse': mse, 'r2': r2}\n    print(f\"{name} -> MSE: {mse:.2f}, R2: {r2:.2f}\")\npredictions_df = pd.DataFrame({\n    'item_sk': X_test['item_sk'].values,\n    'store_sk': X_test['store_sk'].values,\n    'quantity': X_test['quantity'].values,\n    'actual_sales_price': y_test.values,\n    'predicted_rf': results['RandomForest']['y_pred'],\n    'predicted_gb': results['GradientBoosting']['y_pred'],\n    'predicted_lr': results['LinearRegression']['y_pred'],\n    'predicted_hgb': results['HistGradientBoosting']['y_pred']\n})\n\n# Convert Pandas DF to Snowpark DF\npredictions_snowpark = session.create_dataframe(predictions_df)\nsession.sql(\"CREATE DATABASE IF NOT EXISTS MY_DB\").collect()\nsession.sql(\"CREATE SCHEMA IF NOT EXISTS MY_DB.MY_SCHEMA\").collect()\npredictions_snowpark.write.mode(\"overwrite\").save_as_table(\"MY_DB.MY_SCHEMA.SALES_PREDICTIONS\")\npredictions_snowpark\npred_pd = predictions_snowpark.limit(1000).to_pandas()\n\n# Scatter plot: Actual vs Predicted\nplt.figure(figsize=(10,6))\nsns.scatterplot(x='actual_sales_price', y='predicted_rf', data=pred_pd, label='RandomForest', alpha=0.6)\nsns.scatterplot(x='actual_sales_price', y='predicted_gb', data=pred_pd, label='GradientBoosting', alpha=0.6)\nsns.scatterplot(x='actual_sales_price', y='predicted_lr', data=pred_pd, label='LinearRegression', alpha=0.6)\nsns.scatterplot(x='actual_sales_price', y='predicted_hgb', data=pred_pd, label='HistGradientBoosting', alpha=0.6)\nplt.plot([pred_pd['actual_sales_price'].min(), pred_pd['actual_sales_price'].max()],\n         [pred_pd['actual_sales_price'].min(), pred_pd['actual_sales_price'].max()],\n         color='red', linestyle='--', label='Perfect Prediction')\nplt.title(\"Actual vs Predicted Sales Price for Multiple Models\")\nplt.xlabel(\"Actual Sales Price\")\nplt.ylabel(\"Predicted Sales Price\")\nplt.legend()\nplt.show()\n\n# Error distribution for each model\npred_pd['error_rf'] = pred_pd['predicted_rf'] - pred_pd['actual_sales_price']\npred_pd['error_gb'] = pred_pd['predicted_gb'] - pred_pd['actual_sales_price']\npred_pd['error_lr'] = pred_pd['predicted_lr'] - pred_pd['actual_sales_price']\npred_pd['error_hgb'] = pred_pd['predicted_hgb'] - pred_pd['actual_sales_price']\n\nplt.figure(figsize=(10,5))\nsns.histplot(pred_pd['error_rf'], bins=50, color='blue', kde=True, label='RandomForest', alpha=0.5)\nsns.histplot(pred_pd['error_gb'], bins=50, color='green', kde=True, label='GradientBoosting', alpha=0.5)\nsns.histplot(pred_pd['error_lr'], bins=50, color='orange', kde=True, label='LinearRegression', alpha=0.5)\nsns.histplot(pred_pd['error_hgb'], bins=50, color='purple', kde=True, label='HistGradientBoosting', alpha=0.5)\nplt.title(\"Prediction Error Distribution for Multiple Models\")\nplt.xlabel(\"Error\")\nplt.ylabel(\"Count\")\nplt.legend()\nplt.show()\n",
   "execution_count": null
  }
 ]
}